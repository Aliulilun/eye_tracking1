================================================================================
✅ 第四階段完成：神經網絡推理
Stage 4 Completed: Neural Network Inference
================================================================================

📅 完成時間: 2026-01-29

================================================================================
📦 新增文件
================================================================================

1. stages/stage4_gaze_network.py (主要實現)
   ✓ GazeNetwork 類（基於 ResNet-50）
   ✓ GazeEstimator 類（推理器）
   ✓ 載入 ETH-XGaze 預訓練模型
   ✓ 圖像預處理（ImageNet 正規化）
   ✓ 視線角度預測（pitch, yaw）
   ✓ 批量推理支援
   ✓ 視線方向可視化

2. test_stage4.py (測試腳本)
   ✓ 階段 1+2+3+4 完整整合
   ✓ 圖片測試
   ✓ 網路攝像頭即時測試
   ✓ 雙窗口顯示（原始+視線）

================================================================================
🎯 核心功能
================================================================================

輸入:
  - 正規化圖像 (224, 224, 3) RGB - 來自第三階段

處理: 
  ResNet-50 神經網絡推理
  - ImageNet 預訓練基礎
  - ETH-XGaze 微調權重
  - 2048 維特徵提取
  - 2D 視線角度預測

輸出:
  - gaze_angles: [pitch, yaw] 弧度
  - gaze_angles_deg: [pitch, yaw] 度
  
視線角度定義:
  - Pitch (俯仰): 向上為正，向下為負
  - Yaw (偏航): 向左為負，向右為正

================================================================================
🚀 快速使用
================================================================================

測試獨立第四階段:
  $ source .venv/bin/activate
  $ python stages/stage4_gaze_network.py

測試階段 1+2+3+4 完整流程（網路攝像頭，推薦）:
  $ python test_stage4.py --mode webcam

測試階段 1+2+3+4 完整流程（圖片）:
  $ python test_stage4.py --mode image --input test_images/face.jpg

代碼使用:
  from stages.stage4_gaze_network import GazeEstimator
  
  estimator = GazeEstimator(config={
      'model_path': 'models/epoch_24_ckpt.pth.tar',
      'use_gpu': True  # 如果有 GPU
  })
  
  result = estimator.estimate(normalized_image)
  
  if result['success']:
      pitch = result['gaze_angles_deg'][0]  # 俯仰角（度）
      yaw = result['gaze_angles_deg'][1]    # 偏航角（度）
      print(f"Gaze: Pitch={pitch:.1f}°, Yaw={yaw:.1f}°")

================================================================================
🤖 模型架構
================================================================================

網絡結構:
  ResNet-50 (卷積骨幹)
    ├─ conv1 + bn1 + relu + maxpool
    ├─ layer1 (3 個 Bottleneck)
    ├─ layer2 (4 個 Bottleneck)
    ├─ layer3 (6 個 Bottleneck)
    ├─ layer4 (3 個 Bottleneck)
    ├─ avgpool (全局平均池化)
    └─ 輸出: 2048 維特徵
  
  Gaze FC Layer
    └─ Linear(2048 → 2)
    └─ 輸出: [pitch, yaw]

參數量: ~25M (ResNet-50) + 4K (gaze fc) ≈ 25M

預訓練模型:
  - 文件: epoch_24_ckpt.pth.tar
  - 訓練 Epoch: 25
  - 數據集: ETH-XGaze
  - 大小: ~97 MB

================================================================================
📐 圖像預處理
================================================================================

輸入要求:
  - 尺寸: 224×224 像素
  - 格式: RGB
  - 來源: 第三階段正規化輸出

預處理步驟:
  1. BGR → RGB 轉換
  2. 像素值歸一化: [0, 255] → [0, 1]
  3. ImageNet 標準正規化:
     mean = [0.485, 0.456, 0.406]
     std  = [0.229, 0.224, 0.225]
  4. 添加批次維度: (3, 224, 224) → (1, 3, 224, 224)

================================================================================
🔗 與其他階段的連接
================================================================================

從第三階段接收:
  [Stage 3] → normalized_image (224, 224, 3)

輸出給第五階段:
  [Stage 4] → gaze_angles [pitch, yaw] 弧度
  
完整數據流:
  原始圖像 → [S1] 特徵點 → [S2] 姿態 → [S3] 正規化 
  → [S4] 視線角度 → [S5] 3D 向量

================================================================================
📝 配置參數
================================================================================

config = {
    'model_path': 'models/epoch_24_ckpt.pth.tar',  # 模型路徑
    'device': 'cuda',          # 'cuda' 或 'cpu'
    'use_gpu': True            # 是否使用 GPU（向後兼容）
}

GPU vs CPU:
  - GPU: ~5-10 ms per image (推薦)
  - CPU: ~50-100 ms per image

================================================================================
✨ 特色功能
================================================================================

1. 自動設備選擇
   - 自動檢測 CUDA 可用性
   - CPU 降級支援

2. 批量推理
   - 支援多張圖像同時處理
   - 提高吞吐量

3. 視線可視化
   - draw_gaze_on_image() 方法
   - 在圖像上繪製視線箭頭

4. 彈性模型載入
   - 支援多種 checkpoint 格式
   - 'model_state', 'state_dict', 或直接權重

5. 錯誤處理
   - 模型文件檢查
   - GPU 可用性驗證
   - 輸入尺寸驗證

================================================================================
🔄 專案進度更新
================================================================================

總進度: 24/26 文件完成 (92.3%)

✅ 已完成階段:
  - [1/5] 第一階段：人臉檢測與特徵點定位 ✅
  - [2/5] 第二階段：頭部姿態估計 ✅
  - [3/5] 第三階段：圖像正規化 ✅
  - [4/5] 第四階段：神經網絡推理 ✅

⚠️ 待實現階段:
  - [5/5] 第五階段：視線向量轉換

進度: 80% 完成 (4/5 階段)

================================================================================
📊 性能指標
================================================================================

推理速度:
  - GPU (CUDA): ~5-10 ms per image
  - CPU: ~50-100 ms per image
  - 批量處理: 可提升 2-3倍

記憶體:
  - 模型: ~100 MB (GPU VRAM 或 RAM)
  - 單張圖像: ~1 MB
  - 批量 (32): ~32 MB

精度:
  - ETH-XGaze 測試集誤差: ~4-5° (平均角度誤差)
  - Within-dataset: 更高精度
  - Cross-dataset: 可能需要微調

即時性能:
  - 單獨 Stage 4: ~5-10 ms (GPU)
  - 完整流程 (Stage 1-4): ~50-100 ms (GPU)
  - 可達 10-20 FPS（完整流程）

================================================================================
🎓 技術細節
================================================================================

ResNet-50 架構:
  - Bottleneck 結構: 1×1, 3×3, 1×1 卷積
  - 殘差連接: x + F(x)
  - Batch Normalization
  - ReLU 激活

視線估計:
  - 回歸問題（非分類）
  - 輸出: 連續角度值
  - 損失函數（訓練時）: MSE 或 Angular Loss

坐標系統:
  - Pitch = 0°, Yaw = 0°: 正前方
  - Pitch > 0°: 向上看
  - Pitch < 0°: 向下看
  - Yaw > 0°: 向右看
  - Yaw < 0°: 向左看

================================================================================
⏭️ 下一步：第五階段
================================================================================

準備實現第五階段：視線向量轉換

功能:
  - 將 (pitch, yaw) 轉為 3D 單位向量
  - 三角函數計算
  - 向量歸一化
  - 可視化支援

公式:
  x = -cos(pitch) * sin(yaw)
  y = -sin(pitch)
  z = -cos(pitch) * cos(yaw)

告訴 AI:
  "開始實現第五階段"

================================================================================
📚 相關文檔
================================================================================

- models/epoch_24_ckpt.pth.tar: 預訓練模型 (~97 MB)
- stages/stage4_gaze_network.py: 源代碼
- test_stage4.py: 測試腳本（1+2+3+4 整合）

輸出文件（測試生成）:
  - output/test_gaze_estimation.jpg: 視線方向可視化
  - output/test_stage4_original.jpg: 原始圖像+標註
  - output/test_stage4_normalized_gaze.jpg: 正規化+視線

================================================================================

第四階段完成！只剩最後一個階段了！🎉

試試看: source .venv/bin/activate && python test_stage4.py --mode webcam

